{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9aa8c7d-ada6-43e1-9ca8-f6a6c999b5dc",
   "metadata": {},
   "source": [
    "Data Acquisition\n",
    "Our first step is to start a connection with the SAS servers. We use the \"SASPy\" Python package (installed locally) and its SASsession method to establish this connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdba714-dae7-475f-88cd-9c4fbef8cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import saspy\n",
    "\n",
    "sas_session = saspy.SASsession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d93ab63-c521-4318-8510-9e83f94ce0a8",
   "metadata": {},
   "source": [
    "With the connection established, we can use the submit method to run SAS code from our Python interface. \n",
    "This method returns the SAS output and log message as a Python dictionary which can then be queried for either component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d1ad1-a5d1-4005-b9b0-80ad2ff45430",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = sas_session.submitLST(\n",
    "             \"\"\"\n",
    "                filename nyt_url url 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv';\n",
    "                data us_counties_nyt;\n",
    "                    length Date 8 County $ 30 statename $ 30 FIPS $ 6 Cases 8 Deaths 8 WeekOf 8;\n",
    "                    format Date date9. WeekOf date9.;\n",
    "                    infile nyt_url dlm=',' missover dsd firstobs=2;\n",
    "                    input date : yymmdd10.\n",
    "                        county\n",
    "                        statename\n",
    "                        FIPS\n",
    "                        cases\n",
    "                        deaths;\n",
    "                    /* Adding Week ending value for easier summary later */\n",
    "                    WeekOf = intnx('week',date,0,'E');\n",
    "                run;\n",
    "             \"\"\",\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7fd9e-f22e-42a8-afef-7fc68c8c2a5f",
   "metadata": {},
   "source": [
    "To view the SAS log of the previous operation, you would run the command print(results_dict[\"LOG\"]) in Python.\n",
    "\n",
    "SAS has a built-in data set with information about the US, including the 2-letter state codes. We will use an inner join method using a proc sql in SAS to attach \n",
    "this 2-letter code to our data rows. We specifically use an inner join as the NYT data set includes data on some US territories which we wish to exclude from our \n",
    "analysis in order to focus only on the US states.\n",
    "\n",
    "In the last line, we use the sd2df method on our SAS session to move the data from SAS to Python for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94735461-b25e-47bc-a8e8-fe61d34d6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = sas_session.submit(\n",
    "             \"\"\"\n",
    "            proc sql noprint;\n",
    "             create table NYT_joined as\n",
    "                select nyt.Date, nyt.County, nyt.statename as State, usd.Statecode as StateCode, nyt.Cases, nyt.Deaths\n",
    "                from work.US_COUNTIES_NYT as nyt inner join sashelp.us_data as usd\n",
    "                on nyt.statename=usd.statename;\n",
    "            quit;\n",
    "             \"\"\",\n",
    "             )\n",
    "\n",
    "nyt_df = sas_session.sd2df(\"NYT_joined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe7ead-f32c-470f-b60e-55a3c4cf28a2",
   "metadata": {},
   "source": [
    "Now that we have the data available in Python, we will load the various Python packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777f3aa-0fe8-471e-a3b7-6e2e0b27bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for type-hinting in function definitions:\n",
    "from typing import List, Dict  \n",
    "\n",
    "# some standard imports from Python for this \n",
    "# type of work\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# some nice imports to make life easier\n",
    "# 1) make matplotlib aware of Pandas DateTime format\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "# 2) create nicer date formatting in plots\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd3614-46d3-488e-b80c-4651853a27fa",
   "metadata": {},
   "source": [
    "Since the source data set we imported lists data from various counties separately, we first want to simplify our work by adding up all the cases \n",
    "and deaths in each state so that we have only one row of data per state per date. Since this is a common class of problem, we will write a small \n",
    "function to do this task for us. This method is similar to writing and using a macro in SAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcba92c-6570-4e6e-ac48-21da91e942c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_state_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to process the initial data in two ways:\n",
    "    1) Filter down the columns to the important ones, dropping\n",
    "       columns that we don't need for our analysis. \n",
    "    2) Each state is broken down into counties in the NYT data set,\n",
    "       but we want state level information. We sum across the counties\n",
    "       in the state.\n",
    "    Overall, this function is comparable to a \"proc freq\"\n",
    "    in SAS.\n",
    "    \"\"\"\n",
    "    \n",
    "    # filter out unnecessary information. Think of a SAS 'keep' statement.\n",
    "    df = df.filter(['Date', 'State','Cases','Deaths', 'StateCode'])\n",
    "    \n",
    "    # sums up the data by 'Date', 'State, 'Statecode',\n",
    "    # - this returns state-level 'cases' and 'deaths'\n",
    "    short = df.groupby(['Date', 'State', 'StateCode'],\n",
    "                        as_index=False).sum()\n",
    "    return short\n",
    "\n",
    "# call our function to apply the manipulation from the \n",
    "# `make_state_summary` function.\n",
    "df = make_state_summary(nyt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76777fbd-9a1e-4006-8bed-c83640b72d60",
   "metadata": {},
   "source": [
    "Let's verify the data types to make sure we have everything we need. It is important that the Date variable is listed as datetime64[ns] as opposed to \n",
    "as object, which is a string format as opposed to the numeric date format we want. If this variable is listed as an object, we can run the line \n",
    "df.Date = pd.to_datetime(df.Date) to fix this problem. We run the conditional fix and print the data types of all columns to make sure we have the \n",
    "correct types for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160189d-fbf3-4eaf-87b6-1e3d85a24fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that Date is not a string format,\n",
    "# fix it otherwise.\n",
    "if df[\"State\"].dtype==df[\"Date\"].dtype:\n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d43a7-dd0c-41e0-920e-d394eb2c501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date         datetime64[ns]\n",
    "State                object\n",
    "StateCode            object\n",
    "Cases                 int64\n",
    "Deaths              float64\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbcc5ac-4d70-4594-be2d-686b3ce01db0",
   "metadata": {},
   "source": [
    "Updating our Data Set with the Census Information\n",
    "Since we ultimately want to figure out the number of cases and deaths per 100,000 residents of each state, we use a data set from the census bureau which includes population estimates for 2019. We use the filter method (similar to a keep in SAS) to only load the columns we are interested in, including the actual values from the 2010 census, as well as the Census Bureau's estimates for the year 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac94fa-8a8f-4bea-89f0-c341575266f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_url = \"http://www2.census.gov/programs-surveys/popest/datasets/2010-2019/national/totals/nst-est2019-alldata.csv?#\"\n",
    "pop_set = pd.read_csv(census_url).filter(['REGION', 'DIVISION', 'STATE', 'NAME', 'CENSUS2010POP',\n",
    "                          'ESTIMATESBASE2010', 'POPESTIMATE2019'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470edfc-3411-4929-898a-cf9f4ac60258",
   "metadata": {},
   "source": [
    "Now that we have both data sets available in memory, we will calculate the case-load and death-toll for each state and date given the 2019 estimate. The calculated values are appended as new columns to our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19580f9-c531-4d3b-a81f-4f7eeff12487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_case_load(source : pd.DataFrame, \n",
    "                    census : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to update a dataframe to include case-load\n",
    "    and death-toll per 100,000 residents using a census\n",
    "    data set as look-up table for population values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # for loop iterates over all rows in the 'source' dataframe\n",
    "    for index, row in source.iterrows():\n",
    "        state = row[\"State\"]  # looks-up current statename of row\n",
    "        # then looks-up the \"POPESTIMATE2019\" column value associated with \n",
    "        # that state in the `census` dataframe. \n",
    "        pop = census[census.NAME==state][\"POPESTIMATE2019\"].to_numpy()[0]\n",
    "        \n",
    "        # use the population value to calculate cases/deaths per 100.000 residents\n",
    "        cases_per_100k = 1e5*row[\"Cases\"]/pop\n",
    "        deaths_per_100k = 1e5*row[\"Deaths\"]/pop\n",
    "        \n",
    "        # update `source` dataframe with three new column values\n",
    "        source.loc[index,\"Population\"] = pop\n",
    "        source.loc[index,\"CPM\"] = cases_per_100k\n",
    "        source.loc[index, \"DPM\"] = deaths_per_100k\n",
    "    return source\n",
    "\n",
    "# run the functon to actually apply the calculations\n",
    "# defined in the `update_case_load` function.\n",
    "df = update_case_load(df, pop_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e988dc-bdc5-4374-8101-b7bbb66bcfa0",
   "metadata": {},
   "source": [
    "At this stage, we have two Pandas dataframes in memory - the pop_set dataframe which was used a look-up table for state population information, and the main dataframe df which contains the following columns of information we want for our visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec2c1d-0342-4063-a64d-a0d6ea1e487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5433ad8-d91e-471b-9339-295ce1f2c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date          datetime64[ns]\n",
    "State                 object\n",
    "StateCode             object\n",
    "Cases                  int64\n",
    "Deaths               float64\n",
    "Population           float64\n",
    "CPM                  float64\n",
    "DPM                  float64\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2de2b-5682-487b-8b9e-23e79c5d5bf9",
   "metadata": {},
   "source": [
    "Simple Plot Visualition\n",
    "Let's start with a few simple visualizations to compare different states. To make it easier, we create a short function that subsets the necessary data, followed by a short function to do the plotting with the output data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49306b-8be8-4317-939d-5d36aba5e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_sets(df : pd.DataFrame, States: List) -> Dict:\n",
    "    \"\"\"\n",
    "    This function is similar to a data step in SAS. It takes\n",
    "    in a list of state-codes of interest together with the main\n",
    "    dataframe and returns a dictionary where each statecode is mapped\n",
    "    to a dataframe containing only the information from that state.\n",
    "    \"\"\"\n",
    "    # use a quick dictionary comprehension to subset the data\n",
    "    out_dict = {state : df[df.StateCode==state] for state in States }\n",
    "    return out_dict\n",
    "\n",
    "def line_plot_states(states_of_interest : Dict,\n",
    "                    min_date : str = \"2020-03-01\"):\n",
    "    \"\"\"\n",
    "    Convenience function to do the plotting.\n",
    "    Takes a dictionary of states and a start date and then \n",
    "    makes a line plot of the 'cases per 100,000' variable in\n",
    "    all states listed in the dictionary.\n",
    "    \"\"\"\n",
    "    # define plot size\n",
    "    fig, ax = plt.subplots(figsize=(10,5.625))\n",
    "    \n",
    "    # iterates over the dictionary and adds each state's \n",
    "    # line to the plot\n",
    "    for key, data in states_of_interest.items():\n",
    "        subdata = data[data.Date>=pd.to_datetime(min_date)]\n",
    "        ax.plot(subdata.Date, subdata.CPM, label=key)\n",
    "    ax.legend() # turns on the legend\n",
    "\n",
    "    # make the axes pretty\n",
    "    fig.autofmt_xdate()\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    ax.set_ylabel('Cases per 100,000')\n",
    "\n",
    "    plt.show(fig) # necessary to display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262d204-98e6-4afe-a13b-870006516a42",
   "metadata": {},
   "source": [
    "Now all we need to do is to create a list of states of interest and pass them to our function, along with an optional start date. Say we are interested in comparing the cases per 100,000 residents over time for several different states. Then our code would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a2ff5-c543-4e1d-9002-e69035e77747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of states, sort it so that the legend is alphabetical\n",
    "# Try out different states!\n",
    "state_list = sorted([\"AZ\", \"CA\", \"NC\", \"NJ\", \"AR\"])\n",
    "\n",
    "# get the dictionary of state data out\n",
    "states_of_interest = state_sets(df, state_list)\n",
    "\n",
    "# does the plotting\n",
    "line_plot_states(states_of_interest, \"2020-09-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be9cbf-d38a-4ef3-b147-74ec68520e2d",
   "metadata": {},
   "source": [
    "Making the Map\n",
    "Making maps and plotting over them is hard. Luckily, SAS has a few special procedures available for this. To make our work easier, we will first collect the necessary information for the map from our Python data set and then export it to SAS for plotting. We'll pick data corresponding to a single date and upload the data set to SAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13774adf-3f90-4da3-aa20-365ac774c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dates of interest\n",
    "# note that the SAS code below expects only one date,\n",
    "# so if you choose to make a list of multiple dates here,\n",
    "# please also update the SAS code below to pick a specific\n",
    "# date for plotting.\n",
    "# Use format 'YYYY-MM-DD' for the dates\n",
    "dates_of_interest = [\"2021-06-01\"]\n",
    "\n",
    "# uses the above list to subset the dataframe\n",
    "sub_df = df[df.Date.isin(dates_of_interest)]\n",
    "\n",
    "# uploads the dataframe to SAS under the name\n",
    "# work.map_data\n",
    "sas_session.df2sd(sub_df, table=\"map_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44c5cf-b1b0-4536-9b3a-d0c75be0b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "Libref  = WORK\n",
    "Table   = map_data\n",
    "Dsopts  = {}\n",
    "Results = Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c263a6-1feb-4717-9c59-c1c410cab958",
   "metadata": {},
   "source": [
    "We first want to make a choropleth map of the situation. This would allow us to use a color scheme to differentiate between different classes of states, based on the CPM value. Well, gmap to the rescue. We will use the midpoints=old to use a the Nelder algorithm to determine the appropriate ranges and midpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1ee7e-5781-4a35-95ef-7653d4dd22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas_session\n",
    "\n",
    "proc gmap data=work.map_data map=mapsgfk.us all;\n",
    "    id STATECODE;\n",
    "    format CPM COMMA10.;\n",
    "    choro CPM / midpoints=old;\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb35ba8-bb4a-4137-80ff-8ac1800d1b76",
   "metadata": {},
   "source": [
    "By changing the code slightly, we can also create a gradient map of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bda343-719b-454d-95a7-343b99e7afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas_session\n",
    "\n",
    "proc sgmap mapdata=mapsgfk.us maprespdata=map_data;\n",
    "    choromap cpm / mapid=statecode name='choro';\n",
    "    format cpm COMMA10.;\n",
    "    gradlegend 'choro' / title='Cumulative Cases per 100,000' extractscale;\n",
    "run;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
